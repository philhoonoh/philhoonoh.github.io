@misc{oh2025parallelkeyvaluecachefusion,
      title={Parallel Key-Value Cache Fusion for Position Invariant RAG},
      author={Philhoon Oh and Jinwoo Shin and James Thorne},
      year={2025},
      abbr={Under Review},
      eprint={2501.07523},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.07523},
      bibtex_show = {false},
}

@inproceedings{kim-etal-2024-click,
    title = "{CLI}c{K}: A Benchmark Dataset of Cultural and Linguistic Intelligence in {K}orean",
    author = "Kim, Eunsu  and
      Suk, Juyoung  and
      Oh, Philhoon  and
      Yoo, Haneul  and
      Thorne, James  and
      Oh, Alice",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.296/",
    pages = "3335--3346",
    abstract = "Despite the rapid development of large language models (LLMs) for the Korean language, there remains an obvious lack of benchmark datasets that test the requisite Korean cultural and linguistic knowledge. Because many existing Korean benchmark datasets are derived from the English counterparts through translation, they often overlook the different cultural contexts. For the few benchmark datasets that are sourced from Korean data capturing cultural knowledge, only narrow tasks such as hate speech detection are offered. To address this gap, we introduce a benchmark of Cultural and Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs. CLIcK sources its data from official Korean exams and textbooks, partitioning the questions into eleven categories under the two main categories of language and culture. For each instance in click, we provide fine-grained annotation of which cultural and linguistic knowledge is required to correctly answer the question. Using CLIcK, we test 13 language models to assess their performance. Our evaluation uncovers insights into their performances across the categories, as well as the diverse factors affecting their comprehension. CLIcK offers the first large-scale comprehensive Korean-centric analysis of LLMs' proficiency in Korean language and culture.",
    bibtex_show=true,
    selected={true},
}

@inproceedings{oh-thorne-2023-detrimental,
    title = "Detrimental Contexts in Open-Domain Question Answering",
    author = "Oh, Philhoon  and
      Thorne, James",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.776",
    doi = "10.18653/v1/2023.findings-emnlp.776",
    pages = "11589--11605",
    abbr={EMNLP},
    selected={true},
    arxiv={2310.18077},
    bibtex_show=true,
}

@inproceedings{lee-etal-2023-knowledge,
    title = "Knowledge Corpus Error in Question Answering",
    author = "Lee, Yejoon  and
      Oh, Philhoon  and
      Thorne, James",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.616",
    doi = "10.18653/v1/2023.findings-emnlp.616",
    pages = "9183--9197",
    abbr={EMNLP},
    selected={true},
    arxiv={2310.18076},
    bibtex_show=true,
}
